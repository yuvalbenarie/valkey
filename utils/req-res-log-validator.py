#!/usr/bin/env python3
import argparse
import collections
import datetime
import functools
import glob
import multiprocessing
import pathlib
import sys
import time
import typing

import req_res_validator as req_res_validator_utils

"""
The purpose of this file is to validate the reply_schema values of COMMAND DOCS.
Basically, this is what it does:
1. Goes over req-res files, generated by redis-servers, spawned by the testsuite (see logreqres.c)
2. For each request-response pair, it validates the response against the request's reply_schema (obtained from COMMAND DOCS)

This script spins up a valkey-server and a valkey-cli in order to obtain COMMAND DOCS.

In order to use this file you must run the redis testsuite with the following flags:
./runtest --dont-clean --force-resp3 --log-req-res

And then:
./utils/req-res-log-validator.py

The script will fail only if:
1. One or more of the replies doesn't comply with its schema.
2. One or more of the commands in COMMANDS DOCS doesn't have the reply_schema field (with --fail-missing-reply-schemas)
3. The testsuite didn't execute all of the commands (with --fail-commands-not-all-hit)

Future validations:
1. Fail the script if one or more of the branches of the reply schema (e.g. oneOf, anyOf) was not hit.
"""

IGNORED_COMMANDS = {
    # Commands that don't work in a req-res manner (see logreqres.c)
    "debug",  # because of DEBUG SEGFAULT
    "sync",
    "psync",
    "monitor",
    "subscribe",
    "unsubscribe",
    "ssubscribe",
    "sunsubscribe",
    "psubscribe",
    "punsubscribe",
    # Commands to which we decided not write a reply schema
    "pfdebug",
    "lolwut",
}

# Figure out where the sources are
SRC_DIR = str((pathlib.Path(__file__).parent.parent / "src").absolute().resolve())
TESTS_DIR = str((pathlib.Path(__file__).parent.parent / "tests").absolute().resolve())


def report_missing_schemas(docs: typing.Dict[str, typing.Any], fail_missing_reply_schemas: bool) -> None:
    missing_schema = tuple(
        command for command, doc in docs.items()
        if "reply_schema" not in doc and command not in IGNORED_COMMANDS
    )
    if not missing_schema:
        return

    print("WARNING! The following commands are missing a reply_schema:")
    for command in sorted(missing_schema):
        print(f"  {command}")

    if fail_missing_reply_schemas:
        print("ERROR! at least one command does not have a reply_schema")
        sys.exit(1)


def get_command_counter_from_reqres_files(docs: typing.Dict[str, typing.Any]) -> typing.Dict[str, int]:
    command_counter = collections.Counter()

    # Obtain all the files to processes
    path_patterns = (
        f'{TESTS_DIR}/tmp/*/*.reqres',
        f'{TESTS_DIR}/cluster/tmp/*/*.reqres',
        f'{TESTS_DIR}/sentinel/tmp/*/*.reqres',
    )
    paths = tuple(path for path_pattern in path_patterns for path in glob.glob(path_pattern))

    def process_reqres_file(path: str) -> typing.Dict[str, int]:
        processor = req_res_validator_utils.req_res_file_processors.CommandCounterProcessor(
            docs=docs,
            path=path,
            ignored_commands=IGNORED_COMMANDS,
        )
        processor.process()
        return processor.results

    start = time.perf_counter()

    # Spin several processes to handle the files in parallel
    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
        file_processor_method = functools.partial(process_reqres_file, docs)
        # pool.map blocks until all the files have been processed
        for result in pool.map(file_processor_method, paths):
            command_counter.update(result)

    elapsed = datetime.timedelta(seconds=time.perf_counter() - start)
    print(f"Done. ({elapsed})")

    return dict(command_counter)


def report_command_counter(
        docs: typing.Dict[str, typing.Any],
        command_counter: typing.Dict[str, int],
        verbose: bool,
        fail_commands_not_all_hit: bool,
) -> None:
    print("Hits per command:")
    for command, count in sorted(command_counter.items()):
        print(f"  {command}: {count}")

    commands_with_zero_hits = set(set(docs.keys()) - set(command_counter.keys()) - set(IGNORED_COMMANDS))
    if not commands_with_zero_hits:
        return

    if verbose:
        print("WARNING! The following commands were not hit at all:")
        for command in sorted(commands_with_zero_hits):
            print(f"  {command}")

    if fail_commands_not_all_hit:
        print("ERROR! at least one command was not hit by the tests")
        sys.exit(1)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description='validates the reply_schema values of COMMAND DOCS')

    parser.add_argument('--server', type=str, default=f'{SRC_DIR}/valkey-server')
    parser.add_argument('--port', type=int, default=6534)
    parser.add_argument('--cli', type=str, default=f'{SRC_DIR}/valkey-cli')
    parser.add_argument('--module', type=str, action='append', default=[])
    parser.add_argument('--verbose', action='store_true')
    parser.add_argument('--fail-commands-not-all-hit', action='store_true')
    parser.add_argument('--fail-missing-reply-schemas', action='store_true')

    return parser.parse_args()


def main() -> None:
    args = parse_args()

    schemas_fetcher = req_res_validator_utils.SchemasFetcher(cli_exec=args.cli, server_exec=args.server, port=args.port)
    docs = schemas_fetcher.fetch_from_server(modules=args.module)
    docs.update(schemas_fetcher.fetch_from_sentinel())

    report_missing_schemas(docs=docs, fail_missing_reply_schemas=args.fail_missing_reply_schemas)

    command_counter = get_command_counter_from_reqres_files(docs=docs)
    report_command_counter(
        docs=docs,
        command_counter=command_counter,
        verbose=args.verbose,
        fail_commands_not_all_hit=args.fail_commands_not_all_hit,
    )


if __name__ == '__main__':
    main()
